syntax = "proto2";

package ml.optimizer;

// This message defines a large part of the optimizers extra parameters.
// Next id: 5
message OptimizerParameters {
  enum Method {
    // First-order gradient descent method.
    GRADIENT = 0;

    // BFGS algorithm.
    BFGS = 1;

    // Limited memory BFGS algorithm.
    LBFGS = 2;
  }

  // Optimizer algorithm.
  optional Method method = 1 [default = GRADIENT];
  
  // Stochastic gradient descent mini-batch size.
  optional int64 batch_size = 2 [default = 1];

  // L2 regularization.
  optional double l2_regularization = 3 [default = 0.0];
  
  // If true, choose step sizes via backtracking line search.
  optional bool bt_line_search = 4 [default = false];

  // Backtracking line search constant. (0 <= alpha <= 0.5)
  optional double bt_line_search_alpha = 5 [default = 0.3];

  // Backtracking line search constant. (0 <= beta <= 1)
  optional double bt_line_search_beta = 6 [default = 0.8];

  extensions 100 to max;
}